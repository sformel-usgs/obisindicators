{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce335cc1-8844-4de0-b5db-9721a6a887ae",
   "metadata": {},
   "source": [
    "I haven't been able to get Jupyter notebooks working yet with the USGS HPCs, but this cluster can't handle the GBIF data.  So I'm trying this manually in Denali, on a single node, to see if I can make progress."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ad9759-ac5c-4fc5-935f-cf85bd7f1bdb",
   "metadata": {},
   "source": [
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5cb7f266-18d8-4690-a4d0-bbadf1d1625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fsspec\n",
    "import dask.dataframe as dd\n",
    "import intake\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from dask.distributed import LocalCluster, Client\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3b6c107-f0b5-4ed1-b6b1-efa4809962e7",
   "metadata": {},
   "source": [
    "#### Start as Dask client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61563b2-e996-421c-9a3c-d9a680ac6a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On Denali\n",
    "#from dask.distributed import LocalCluster, Client\n",
    "#cluster = LocalCluster(threads_per_worker=1)\n",
    "#client = Client(cluster)\n",
    " \n",
    "#This didn't work.  It spun up the cluster but crashed on the first command.  Let's try it without the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39b3c46c-2618-49f7-98e5-c768619e9d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Region: us-west-2\n",
      "No Cluster running.\n",
      "Starting new cluster.\n",
      "{}\n",
      "Setting Cluster Environment Variable AWS_DEFAULT_REGION us-west-2\n",
      "Setting Fixed Scaling workers=30\n",
      "Reconnect client to clear cache\n",
      "client.dashboard_link (for new browser tab/window or dashboard searchbar in Jupyterhub):\n",
      "https://jupyter.qhub.esipfed.org/gateway/clusters/dev.ba22da0d08f74fd99f2884edd0040909/status\n",
      "Propagating environment variables to workers\n",
      "Using environment: users/pangeo\n"
     ]
    }
   ],
   "source": [
    "#On qhub\n",
    "# sys.path.append(os.path.join(os.environ['HOME'],'shared','users','lib'))\n",
    "# import ebdpy as ebd\n",
    "# aws_profile = 'esip-qhub'\n",
    "# ebd.set_credentials(profile=aws_profile)\n",
    "\n",
    "# aws_region = 'us-west-2'\n",
    "# endpoint = f's3.{aws_region}.amazonaws.com'\n",
    "# ebd.set_credentials(profile=aws_profile, region=aws_region, endpoint=endpoint)\n",
    "# worker_max = 30\n",
    "# client,cluster = ebd.start_dask_cluster(profile=aws_profile, worker_max=worker_max, \n",
    "#                                         region=aws_region, use_existing_cluster=True,\n",
    "#                                         adaptive_scaling=False, wait_for_cluster=False, \n",
    "#                                         worker_profile='Medium Worker', propagate_env=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad658fc-ca91-4c26-9a47-d1dd493757b1",
   "metadata": {},
   "source": [
    "_From the above output, copy and paste the url for the daskboard, minus the '/status' into the bar at the top of the dask window on the left of jupyterlab._\n",
    "\n",
    "It might take 3-5 min for it to spin up."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f46b61-2e20-496d-b73d-6d28e8216f64",
   "metadata": {},
   "source": [
    "## Explore dask/data structure\n",
    "\n",
    "Following tips and tutorials from these:\n",
    "- https://www.youtube.com/watch?v=6EozEvfTcBI\n",
    "- https://www.youtube.com/watch?v=LKIRAzsqLb0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6afc0c0-7a16-4442-bdc6-8e7120f79c05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fs = fsspec.filesystem('s3', anon=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57640208-d35e-4b3c-83e6-c36aa4434eda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gbif-open-data-us-east-1/index.html', 'gbif-open-data-us-east-1/occurrence']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fs.ls('s3://gbif-open-data-us-east-1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4208cbd2-965a-4dd6-b72e-bc6235c4d011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gbif-open-data-us-east-1/occurrence/2022-12-01'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#day_list = fs.ls('s3://gbif-open-data-us-east-1/occurrence/')\n",
    "#day_list[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c5cda2b7-e5cf-49a8-a428-48c13d1489dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gbif-open-data-us-east-1/occurrence/2022-12-01/citation.txt',\n",
       " 'gbif-open-data-us-east-1/occurrence/2022-12-01/occurrence.parquet']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fs.ls(day_list[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9df0c9bf-ab95-4a51-8b0a-fd61620ad4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = dd.read_parquet('s3://gbif-open-data-us-east-1/occurrence/2022-11-01/occurrence.parquet/*', \n",
    "#                      storage_options={\"anon\": True}, \n",
    "#                      engine = 'fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c407a8-e7a7-4811-88f8-58b5eee1fa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Working locally in Denali\n",
    "\n",
    "df = dd.read_parquet('/caldera/projects/css/sas/bio/spec_obs/gbif/snapshot/occurrence.parquet/*', \n",
    "                      engine = 'fastparquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09db72f5-b4a4-46ed-a3f1-f0d8fdd472f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gbifid</th>\n",
       "      <th>datasetkey</th>\n",
       "      <th>occurrenceid</th>\n",
       "      <th>kingdom</th>\n",
       "      <th>phylum</th>\n",
       "      <th>class</th>\n",
       "      <th>order</th>\n",
       "      <th>family</th>\n",
       "      <th>genus</th>\n",
       "      <th>species</th>\n",
       "      <th>...</th>\n",
       "      <th>identifiedby</th>\n",
       "      <th>dateidentified</th>\n",
       "      <th>license</th>\n",
       "      <th>rightsholder</th>\n",
       "      <th>recordedby</th>\n",
       "      <th>typestatus</th>\n",
       "      <th>establishmentmeans</th>\n",
       "      <th>lastinterpreted</th>\n",
       "      <th>mediatype</th>\n",
       "      <th>issue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3534344612</td>\n",
       "      <td>4fa7b334-ce0d-4e88-aaae-2e0c138d049e</td>\n",
       "      <td>URN:catalog:CLO:EBIRD:OBS1178111150</td>\n",
       "      <td>Animalia</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Aves</td>\n",
       "      <td>Passeriformes</td>\n",
       "      <td>Cardinalidae</td>\n",
       "      <td>Passerina</td>\n",
       "      <td>Passerina ciris</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>CC_BY_4_0</td>\n",
       "      <td>None</td>\n",
       "      <td>[obsr455843]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-09-08 14:35:29.672</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3534604870</td>\n",
       "      <td>4fa7b334-ce0d-4e88-aaae-2e0c138d049e</td>\n",
       "      <td>URN:catalog:CLO:EBIRD_CAN:OBS1179048592</td>\n",
       "      <td>Animalia</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Aves</td>\n",
       "      <td>Passeriformes</td>\n",
       "      <td>Emberizidae</td>\n",
       "      <td>Melospiza</td>\n",
       "      <td>Melospiza lincolnii</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>CC_BY_4_0</td>\n",
       "      <td>None</td>\n",
       "      <td>[obsr232608]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-09-08 14:35:31.349</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3534885128</td>\n",
       "      <td>4fa7b334-ce0d-4e88-aaae-2e0c138d049e</td>\n",
       "      <td>URN:catalog:CLO:EBIRD:OBS1180074221</td>\n",
       "      <td>Animalia</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Aves</td>\n",
       "      <td>Passeriformes</td>\n",
       "      <td>Parulidae</td>\n",
       "      <td>Setophaga</td>\n",
       "      <td>Setophaga petechia</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>CC_BY_4_0</td>\n",
       "      <td>None</td>\n",
       "      <td>[obsr313985]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-09-08 14:35:34.634</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3535431386</td>\n",
       "      <td>4fa7b334-ce0d-4e88-aaae-2e0c138d049e</td>\n",
       "      <td>URN:catalog:CLO:EBIRD:OBS1180952857</td>\n",
       "      <td>Animalia</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Aves</td>\n",
       "      <td>Psittaciformes</td>\n",
       "      <td>Psittacidae</td>\n",
       "      <td>Pionus</td>\n",
       "      <td>Pionus menstruus</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>CC_BY_4_0</td>\n",
       "      <td>None</td>\n",
       "      <td>[obsr754360]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-09-08 14:35:37.436</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3535679644</td>\n",
       "      <td>4fa7b334-ce0d-4e88-aaae-2e0c138d049e</td>\n",
       "      <td>URN:catalog:CLO:EBIRD:OBS1181682586</td>\n",
       "      <td>Animalia</td>\n",
       "      <td>Chordata</td>\n",
       "      <td>Aves</td>\n",
       "      <td>Piciformes</td>\n",
       "      <td>Picidae</td>\n",
       "      <td>Melanerpes</td>\n",
       "      <td>Melanerpes carolinus</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaT</td>\n",
       "      <td>CC_BY_4_0</td>\n",
       "      <td>None</td>\n",
       "      <td>[obsr14802]</td>\n",
       "      <td>[]</td>\n",
       "      <td>None</td>\n",
       "      <td>2022-09-08 14:35:39.348</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       gbifid                            datasetkey  \\\n",
       "0  3534344612  4fa7b334-ce0d-4e88-aaae-2e0c138d049e   \n",
       "1  3534604870  4fa7b334-ce0d-4e88-aaae-2e0c138d049e   \n",
       "2  3534885128  4fa7b334-ce0d-4e88-aaae-2e0c138d049e   \n",
       "3  3535431386  4fa7b334-ce0d-4e88-aaae-2e0c138d049e   \n",
       "4  3535679644  4fa7b334-ce0d-4e88-aaae-2e0c138d049e   \n",
       "\n",
       "                              occurrenceid   kingdom    phylum class  \\\n",
       "0      URN:catalog:CLO:EBIRD:OBS1178111150  Animalia  Chordata  Aves   \n",
       "1  URN:catalog:CLO:EBIRD_CAN:OBS1179048592  Animalia  Chordata  Aves   \n",
       "2      URN:catalog:CLO:EBIRD:OBS1180074221  Animalia  Chordata  Aves   \n",
       "3      URN:catalog:CLO:EBIRD:OBS1180952857  Animalia  Chordata  Aves   \n",
       "4      URN:catalog:CLO:EBIRD:OBS1181682586  Animalia  Chordata  Aves   \n",
       "\n",
       "            order        family       genus               species  ...  \\\n",
       "0   Passeriformes  Cardinalidae   Passerina       Passerina ciris  ...   \n",
       "1   Passeriformes   Emberizidae   Melospiza   Melospiza lincolnii  ...   \n",
       "2   Passeriformes     Parulidae   Setophaga    Setophaga petechia  ...   \n",
       "3  Psittaciformes   Psittacidae      Pionus      Pionus menstruus  ...   \n",
       "4      Piciformes       Picidae  Melanerpes  Melanerpes carolinus  ...   \n",
       "\n",
       "  identifiedby dateidentified    license rightsholder    recordedby  \\\n",
       "0           []            NaT  CC_BY_4_0         None  [obsr455843]   \n",
       "1           []            NaT  CC_BY_4_0         None  [obsr232608]   \n",
       "2           []            NaT  CC_BY_4_0         None  [obsr313985]   \n",
       "3           []            NaT  CC_BY_4_0         None  [obsr754360]   \n",
       "4           []            NaT  CC_BY_4_0         None   [obsr14802]   \n",
       "\n",
       "  typestatus establishmentmeans         lastinterpreted mediatype  issue  \n",
       "0         []               None 2022-09-08 14:35:29.672        []     []  \n",
       "1         []               None 2022-09-08 14:35:31.349        []     []  \n",
       "2         []               None 2022-09-08 14:35:34.634        []     []  \n",
       "3         []               None 2022-09-08 14:35:37.436        []     []  \n",
       "4         []               None 2022-09-08 14:35:39.348        []     []  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "802d3bbc-a2a0-415c-985f-33022ccf565c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112d783b-50bd-4f7f-9f54-1b0c0d7327c3",
   "metadata": {},
   "source": [
    "## Some thoughts about the data\n",
    "\n",
    "- Many columns won't be needed.  What's needed are:\n",
    "    - kingdom\n",
    "    - class\n",
    "    - species\n",
    "    - countrycode\n",
    "    - decimallatitude\n",
    "    - decimallongitude\n",
    "    - year\n",
    "\n",
    "- decimallatitude and decimal longitude can be converted to int32 to save memory since (I think) most coordinates aren't accurate beyond 4 or 5 decimal places.\n",
    "\n",
    "Let's check a partition size (in MB). I think it should be aroudn 85 MB, since there are 2021 partitions and the parquet file is ~ 173 GB.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f92c8d8-084c-46a0-830b-471dd91c3cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a single partition\n",
    "#df.partitions[0].memory_usage(deep=True).compute()/1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e8b500c-8fad-4c70-8669-f3ae80a5ceee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3457.245578"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.partitions[0].memory_usage(deep=True).sum().compute()/1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a62341d-2d84-4f5b-9568-5c6fc8649022",
   "metadata": {},
   "source": [
    "Hmm, that returns 3457 MB. Let me try something else. Strange, none of them are very even, and they are all kinds of sizes. The internet tells me \"For example if your dask.dataframe has only one partition then only one core can operate at a time. If you have too many partitions then the scheduler may incur a lot of overhead deciding where to compute each task. Generally you want a few times more partitions than you have cores.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5bfc72e4-969f-4f4d-bf45-830c9e8b326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_list = df.memory_usage_per_partition(deep=True).compute() / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0659047c-5de8-497b-83d2-610f893f945f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4762.149198174"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_sum = part_list.sum()\n",
    "part_sum / 1e3 #in GB. So 4.7TB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6bf647e5-47fb-4881-98ed-5d0dae426622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2356.333101521029"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_mean = part_list.mean()\n",
    "part_mean #2.3 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0405cb24-fc13-46a7-9393-6c900b9c6047",
   "metadata": {},
   "source": [
    "What would be an even split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "19effddf-c4c6-4d92-bc7a-c3c6264bed3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2182.234909026524"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.sqrt(part_sum) # 2.18 GB, with 2182 partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026b9dd8-d014-4dd4-8711-11bfc8c063ed",
   "metadata": {},
   "source": [
    "## More thoughts...\n",
    "\n",
    "- not clear if any of these are horrible, but from the tutorial, it's likely that the objects should be converted to \"string[pyarrow]\"  Not too suprisingly, these are the most expensive.\n",
    "- After thinking about it some more, it's probably not safe to convert float 64 to float32. Too much precision would be lost.\n",
    "- Let's check total memory volume "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4d13311-6dca-44e2-8b07-4aa1f24f3b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import dask\n",
    "\n",
    "#dask.utils.format_bytes(\n",
    "#    df.memory_usage(deep=True).compute().sum()\n",
    "#)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a47354-23f0-47a9-8e3b-8f99257b8a4d",
   "metadata": {},
   "source": [
    "_That took a little while, not sure if it was worth it. It says it's 4.33 TiB, that's much larger than I thought it would be._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1593d6b8-a6b7-4f9d-b1df-ef82326a9c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'datasetkey': 'string[pyarrow]',\n",
       " 'occurrenceid': 'string[pyarrow]',\n",
       " 'kingdom': 'string[pyarrow]',\n",
       " 'phylum': 'string[pyarrow]',\n",
       " 'class': 'string[pyarrow]',\n",
       " 'order': 'string[pyarrow]',\n",
       " 'family': 'string[pyarrow]',\n",
       " 'genus': 'string[pyarrow]',\n",
       " 'species': 'string[pyarrow]',\n",
       " 'infraspecificepithet': 'string[pyarrow]',\n",
       " 'taxonrank': 'string[pyarrow]',\n",
       " 'scientificname': 'string[pyarrow]',\n",
       " 'verbatimscientificname': 'string[pyarrow]',\n",
       " 'verbatimscientificnameauthorship': 'string[pyarrow]',\n",
       " 'countrycode': 'string[pyarrow]',\n",
       " 'locality': 'string[pyarrow]',\n",
       " 'stateprovince': 'string[pyarrow]',\n",
       " 'occurrencestatus': 'string[pyarrow]',\n",
       " 'publishingorgkey': 'string[pyarrow]',\n",
       " 'basisofrecord': 'string[pyarrow]',\n",
       " 'institutioncode': 'string[pyarrow]',\n",
       " 'collectioncode': 'string[pyarrow]',\n",
       " 'catalognumber': 'string[pyarrow]',\n",
       " 'recordnumber': 'string[pyarrow]',\n",
       " 'identifiedby': 'string[pyarrow]',\n",
       " 'license': 'string[pyarrow]',\n",
       " 'rightsholder': 'string[pyarrow]',\n",
       " 'recordedby': 'string[pyarrow]',\n",
       " 'typestatus': 'string[pyarrow]',\n",
       " 'establishmentmeans': 'string[pyarrow]',\n",
       " 'mediatype': 'string[pyarrow]',\n",
       " 'issue': 'string[pyarrow]'}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversions = {}\n",
    "for column, dtype in df.dtypes.items():\n",
    "    if dtype == \"object\":\n",
    "        conversions[column] = \"string[pyarrow]\"\n",
    "        \n",
    "conversions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3428bdfa-ed2f-4535-801d-e2f5daf7120d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(conversions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b752b3-adef-4c59-9c89-0ade61f11feb",
   "metadata": {},
   "source": [
    "**How big is the first partition?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "99799327-1af7-413a-a724-a087a5faf35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.partitions[0].memory_usage(deep=True).compute()/1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58de328f-1889-4c70-9a6d-b0525a8fbe72",
   "metadata": {},
   "source": [
    "Wow, that was significant for the strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0b1a26-490c-4ad7-ae42-9f91513e5e40",
   "metadata": {},
   "source": [
    "## Repartition to recommended size\n",
    "...he talks about this in the video, I tried 256 MiB. Didn't seem to make much of a difference.  I need to read up on this more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7ad0cdb1-c97c-45fe-825e-90133a8cfa30",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.repartition(partition_size=\"256MiB\").persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a582e0-22aa-42d1-959c-39361c9b6c9d",
   "metadata": {},
   "source": [
    "## Further filtering...\n",
    "\n",
    "From this data quality presentation, there are some recommendations about flags and filters to use.\n",
    "\n",
    "- zero-zero coordinates should be removed (although if we're just thinking about USA this isn't a problem)\n",
    "- country coordinate mismatch (under issues) can be used to filter to USA, and otherwise remove spurious data.\n",
    "- remove absence records\n",
    "- remove coordinate invalid records\n",
    "- remove coordinate out of range records\n",
    "- remove fossil records\n",
    "- remove living specimen records (in zoo, botanical gardens)\n",
    "- count and (maybe) remove data in country centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9d7f62d-5963-4d7b-9a37-b49476906200",
   "metadata": {},
   "source": [
    "*Select the columns we need for filtering. First examine values*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0c5da1-f5aa-4289-9f72-e66daa858372",
   "metadata": {},
   "source": [
    "Some memory is saved by converting issue, basisofrecord, kingdom, and countrycode to category...but according to Ayush, there's a known bug with categorical columns when using to_parquet to save the dask dataframe into parquet files. He says, \"It affects some environments (at least it did mine) while transforming the encoding.\"  So we'll avoid back convert these when writing to parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "91704bbb-6ba3-4a07-bb18-6d303d1f28d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['issue'] = df.issue.astype('category')\n",
    "df['basisofrecord'] = df.basisofrecord.astype('category')\n",
    "df['countrycode'] = df.countrycode.astype('category')\n",
    "df['kingdom'] = df.kingdom.astype('category')\n",
    "\n",
    "#df.partitions[0].memory_usage(deep=True).compute()/1000000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8440c366-5a79-46b0-8aa7-802398324a8b",
   "metadata": {},
   "source": [
    "## Find levels\n",
    "\n",
    "Because dask [splits categoricals](https://docs.dask.org/en/stable/dataframe-categoricals.html), if we want to know all possible levels, we need to make them \"known\" first...but this requires scan of the entire data, so not really worth it.  I got the levels by going to GBIF.org and looking at the URL after filtering these with the search tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "6928db38-fcfd-49cb-9f6b-e19a4dcfdfbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.categorize(columns= ['issue', 'basisofrecord'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07bf6f9-e33d-4d92-b50d-b573c16e7244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df[[\"issue\",\n",
    "         \"basisofrecord\",\n",
    "         \"occurrencestatus\",\n",
    "         \"kingdom\",\n",
    "         \"class\",\n",
    "         \"countrycode\",\n",
    "         \"decimallongitude\",\n",
    "         \"decimallatitude\",\n",
    "         \"year\",\n",
    "         \"species\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b7458438-2405-4a30-ad84-80dc8804a77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[~df1['issue'].isin([\"['COUNTRY_COORDINATE_MISMATCH']\",\n",
    "                             \"['RECORDED_DATE_INVALID']\",\n",
    "                             \"['COORDINATE_INVALID']\"])\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "816228f4-30ea-47e3-b68f-f13bd2cb6607",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1['occurrencestatus'] == \"PRESENT\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "bcbf9435-ee3f-4fa0-a020-bf73643e8740",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1['basisofrecord'].isin([\"OBSERVATION\",\n",
    "                                  \"MACHINE_OBSERVATION\",\n",
    "                                  \"HUMAN_OBSERVATION\",\n",
    "                                  \"MATERIAL_SAMPLE\",\n",
    "                                  \"PRESERVED_SPECIMEN\",\n",
    "                                  \"OCCURRENCE\"])\n",
    "       ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089865a3-3bce-43a5-a08c-1f591802fa1c",
   "metadata": {},
   "source": [
    "Let's subset to USA. I learned here that it's necessary to use double quotes aroudn the US."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c306cca-2fb1-444f-a68d-04cf0efa9786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1.countrycode == \"US\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d129a3a5-f3c3-4341-b1ca-8786f3e85125",
   "metadata": {},
   "source": [
    "filter to 2010"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "467b045a-d25f-4bb6-ab59-aa80a6876298",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[df1.year == 2010]\n",
    "df1 = df1[df1.year <= 2019]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bafb72-d830-45f2-b933-ba428def6bd6",
   "metadata": {},
   "source": [
    "Remove unneeded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9bb67f91-439f-49b1-bae5-530e2b520342",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1[[\"kingdom\",\n",
    "         \"class\",\n",
    "         \"decimallongitude\",\n",
    "         \"decimallatitude\",\n",
    "         \"year\",\n",
    "         \"species\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "082ae9d8-2ad9-4b53-bed3-d806f939f503",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kingdom</th>\n",
       "      <th>class</th>\n",
       "      <th>decimallongitude</th>\n",
       "      <th>decimallatitude</th>\n",
       "      <th>year</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Animalia</td>\n",
       "      <td>Aves</td>\n",
       "      <td>-89.28571</td>\n",
       "      <td>38.666687</td>\n",
       "      <td>2010</td>\n",
       "      <td>Buteo jamaicensis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Animalia</td>\n",
       "      <td>Aves</td>\n",
       "      <td>-155.32988</td>\n",
       "      <td>19.644060</td>\n",
       "      <td>2010</td>\n",
       "      <td>Lophura leucomelanos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      kingdom class  decimallongitude  decimallatitude  year  \\\n",
       "170  Animalia  Aves         -89.28571        38.666687  2010   \n",
       "171  Animalia  Aves        -155.32988        19.644060  2010   \n",
       "\n",
       "                  species  \n",
       "170     Buteo jamaicensis  \n",
       "171  Lophura leucomelanos  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head(n = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab16ad04-d247-4021-be26-e25297de71df",
   "metadata": {},
   "source": [
    "After subsetting and repartitioning, the volume in memory is "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "16cf11f0-0a27-412c-859c-81da04818278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.675021"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.partitions[0].memory_usage(deep=True).sum().compute()/1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3802c1-2503-414c-a01f-adc29838741a",
   "metadata": {},
   "source": [
    "Ok, so the one got much smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "65b2294a-0315-4848-90de-b691c39591d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "part_list = df1.memory_usage_per_partition(deep=True).compute() / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "37a2e910-f1c8-46b1-b541-87fd1b7da650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "969.190003"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_sum = part_list.sum()\n",
    "part_sum # 1GB. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7db69b0f-b150-49bd-9d33-f8081d26c9f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.47955962543295405"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_mean = part_list.mean()\n",
    "part_mean #0.5 MB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa84f77d-0ed3-4cea-acb1-b25332391bac",
   "metadata": {},
   "source": [
    "What would be an even split?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "14ed2ddd-cd14-4505-9f63-3221a8475275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.131816570833127"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.sqrt(part_sum) # 31 MB with 31 partitions, but we can handle more than that."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8515c9ff-6f5d-4691-b125-ab8aa20d1139",
   "metadata": {},
   "source": [
    "Drop NA values in species (not totally sure we should drop these as much as aggregate them at genus, but that's a discussion for another day.) and decimallatitude (could use longtitude instead). _Follow up: I think this dropna is really computationally expensive (from watching the workers) but I'm not sure why.  Something to research._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0fdde598-d36d-429b-b28b-b13f64db4ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1 = df1.repartition(partition_size=\"100MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "9cc49133-902d-45a8-bd44-98c21ad58d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-08 23:57:55,063 - distributed.client - ERROR - Exception raised while shutting down cluster dev.ba22da0d08f74fd99f2884edd0040909\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/dask_gateway/client.py\", line 993, in _stop_internal\n",
      "    await self.gateway._stop_cluster(self.name)\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/dask_gateway/client.py\", line 654, in _stop_cluster\n",
      "    await self._request(\"DELETE\", url)\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/dask_gateway/client.py\", line 397, in _request\n",
      "    resp = await session.request(method, url, json=json, **self._request_kwargs)\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/aiohttp/client.py\", line 536, in _request\n",
      "    conn = await self._connector.connect(\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/aiohttp/connector.py\", line 540, in connect\n",
      "    proto = await self._create_connection(req, traces, timeout)\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/aiohttp/connector.py\", line 901, in _create_connection\n",
      "    _, proto = await self._create_direct_connection(req, traces, timeout)\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/aiohttp/connector.py\", line 1152, in _create_direct_connection\n",
      "    hosts = await asyncio.shield(host_resolved)\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/aiohttp/connector.py\", line 874, in _resolve_host\n",
      "    addrs = await self._resolver.resolve(host, port, family=self._family)\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/aiohttp/resolver.py\", line 33, in resolve\n",
      "    infos = await self._loop.getaddrinfo(\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/asyncio/base_events.py\", line 861, in getaddrinfo\n",
      "    return await self.run_in_executor(\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/asyncio/base_events.py\", line 819, in run_in_executor\n",
      "    executor.submit(func, *args), loop=self)\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/concurrent/futures/thread.py\", line 167, in submit\n",
      "    raise RuntimeError('cannot schedule new futures after shutdown')\n",
      "RuntimeError: cannot schedule new futures after shutdown\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-19649' coro=<Client._gather.<locals>.wait() done, defined at /home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py:2119> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py\", line 2128, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-19650' coro=<Client._gather.<locals>.wait() done, defined at /home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py:2119> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py\", line 2128, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-19651' coro=<Client._gather.<locals>.wait() done, defined at /home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py:2119> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py\", line 2128, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-19652' coro=<Client._gather.<locals>.wait() done, defined at /home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py:2119> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py\", line 2128, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-19653' coro=<Client._gather.<locals>.wait() done, defined at /home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py:2119> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py\", line 2128, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-19654' coro=<Client._gather.<locals>.wait() done, defined at /home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py:2119> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py\", line 2128, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-19655' coro=<Client._gather.<locals>.wait() done, defined at /home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py:2119> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py\", line 2128, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-19656' coro=<Client._gather.<locals>.wait() done, defined at /home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py:2119> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py\", line 2128, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-19657' coro=<Client._gather.<locals>.wait() done, defined at /home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py:2119> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py\", line 2128, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n",
      "Task exception was never retrieved\n",
      "future: <Task finished name='Task-19658' coro=<Client._gather.<locals>.wait() done, defined at /home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py:2119> exception=AllExit()>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/conda/users/7d479acd42e90471353def6ca5a8af746b5fc7262141e86e2738676e7087dbc8-20221121-135211-565707-232-pangeo/lib/python3.9/site-packages/distributed/client.py\", line 2128, in wait\n",
      "    raise AllExit()\n",
      "distributed.client.AllExit\n"
     ]
    }
   ],
   "source": [
    "df1 = df1.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a784f79-436d-4f3d-80b2-97d35dd3d5ba",
   "metadata": {},
   "source": [
    "_The above started getting unwieldy with the whole datset, with a lot written to disk.  Repartitioning didn't help and it crashed the cluster. (or at least threw an error about shuting down the cluster)It seems to be able to handle the US 2010s though."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c879f61d-52dd-4780-b2dc-5d80a59e6b44",
   "metadata": {},
   "source": [
    "_It may have helped a little.  There is still a fair amount on disk (in grey) but I think that's going to have to be the way it is because of the size of the cluster.  Check volume below._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6bf7e4-ac6d-4f0c-9b97-cddc6f1f8496",
   "metadata": {},
   "outputs": [],
   "source": [
    "#On Denali, write parquet, just to see.  Keep in mind what Anush said about categoricals.\n",
    "\n",
    "dd.to_parquet(df1, '/caldera/projects/css/sas/bio/spec_obs/gbif/snapshot/US_2010s_occurrence.parquet/*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ed40cd-b285-4a53-ab68-29df5cc5c844",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df2 = df1.groupby([\"year\", \"decimallongitude\",\"decimallatitude\"]).count().persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93040d8d-f293-40d7-a68a-38231c60c5ad",
   "metadata": {},
   "source": [
    "The cluster crashed a few times trying to compute the above.  It got most of the way there, then was killed and started over. It did this three times and then gave up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9108aadc-b89b-4d03-baf2-870159f0a19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#del df1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033415ea-e23d-49c0-a13a-593f4323398d",
   "metadata": {},
   "source": [
    "## Mess around with datashader\n",
    "\n",
    "followed this: https://www.youtube.com/watch?v=LKIRAzsqLb0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25d969c-e15a-4375-b58e-d387bf05df8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import datashader\n",
    "# from datashader import transfer_functions as tf\n",
    "# from datashader.colors import Hot\n",
    "# import holoviews as hv\n",
    "\n",
    "# def render(df1, x_range=(-125, -65), y_range=(24, 50)):\n",
    "#     # Plot\n",
    "#     canvas = datashader.Canvas(\n",
    "#         x_range=x_range,\n",
    "#         y_range=y_range,\n",
    "#     )\n",
    "#     agg = canvas.points(\n",
    "#         source=df, \n",
    "#         x=\"decimallongitude\", \n",
    "#         y=\"decimallatitude\", \n",
    "#         agg=datashader.count(\"kingdom\"),\n",
    "#     )\n",
    "#     return datashader.transfer_functions.shade(agg, cmap=Hot, how=\"eq_hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc96fa7-b6b9-4f07-9905-0aeda02e650d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#render(df1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b538be-da36-4b25-8f00-42fd30625146",
   "metadata": {
    "tags": []
   },
   "source": [
    "## List your clusters, then shut them all down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "085f90d1-b981-4e01-953e-48f4c502ebc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_gateway import Gateway\n",
    "from dask.distributed import Client\n",
    "gateway = Gateway()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bfed25a6-0066-4f01-830b-c91033ff1c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gateway.list_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5f29e3a-e8bf-4190-bf38-0eb4c635dd0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stopped dev.ba22da0d08f74fd99f2884edd0040909\n"
     ]
    }
   ],
   "source": [
    "for cluster in gateway.list_clusters():\n",
    "    gateway.stop_cluster(cluster_name=cluster.name)\n",
    "    print(f'stopped {cluster.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "402c45bc-b260-448d-a238-542f0eeeb1dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gateway.list_clusters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adbfdd24-2f47-49b8-badd-67664754c77a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "users-pangeo",
   "language": "python",
   "name": "conda-env-users-pangeo-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
